services:

  mongodb1:
    image: mongo:6.0
    container_name: mongodb1
    hostname: mongodb1
    ports:
      - "27017:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: example
    command: >
      mongod --replSet rs0 --bind_ip_all --keyFile /data/keyfile --auth
    volumes:
      - mongodb1_data:/data/db
      - ./docker/mongodb/mongodb-keyfile:/data/keyfile:ro
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "rs.isMaster().ismaster"]
      interval: 10s
      timeout: 5s
      retries: 5

    networks:
      - messaging-net

  mongodb2:
    image: mongo:6.0
    container_name: mongodb2
    hostname: mongodb2
    depends_on:
      mongodb1:
        condition: service_healthy
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: example
    command: >
      mongod --replSet rs0 --bind_ip_all --keyFile /data/keyfile --auth
    volumes:
      - mongodb2_data:/data/db
      - ./docker/mongodb/mongodb-keyfile:/data/keyfile:ro
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 3
    networks:
      - messaging-net

  mongodb3:
    image: mongo:6.0
    container_name: mongodb3
    hostname: mongodb3
    depends_on:
      mongodb2:
        condition: service_healthy
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: example
    command: >
      mongod --replSet rs0 --bind_ip_all --keyFile /data/keyfile --auth
    volumes:
      - mongodb3_data:/data/db
      - ./docker/mongodb/mongodb-keyfile:/data/keyfile:ro
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 3
    networks:
      - messaging-net

  mongodb-init:
    image: mongo:6.0
    container_name: mongodb-init
    depends_on:
      mongodb1:
        condition: service_healthy
      mongodb2:
        condition: service_healthy
      mongodb3:
        condition: service_healthy
    command: >
      bash -c "
        echo 'Waiting additional time for all MongoDB nodes to be ready...';
        sleep 15;
        
        echo 'Attempting to initiate replica set...';
        mongosh --host mongodb1 --username root --password example --eval '
          let attempt = 0;
          const maxAttempts = 5;
          let success = false;
          
          while (attempt < maxAttempts && !success) {
            try {
              const status = rs.status();
              if (status.ok) {
                print(\"Replica set already initialized\");
                success = true;
                break;
              }
            } catch (e) {
              if (e.codeName === \"NoReplicationEnabled\" || e.codeName === \"NotYetInitialized\") {
                print(\"Initializing new replica set (attempt \" + (attempt + 1) + \")\");
                try {
                  rs.initiate({
                    _id: \"rs0\",
                    members: [
                      { _id: 0, host: \"mongodb1:27017\", priority: 3 },
                      { _id: 1, host: \"mongodb2:27017\", priority: 2 },
                      { _id: 2, host: \"mongodb3:27017\", priority: 1 }
                    ],
                    settings: {
                      heartbeatIntervalMillis: 2000,
                      electionTimeoutMillis: 10000
                    }
                  });
                  success = true;
                } catch (initError) {
                  print(\"Init attempt failed: \" + initError);
                  attempt++;
                  sleep(5000);
                }
              } else {
                throw e;
              }
            }
          }
          
          if (!success) {
            throw new Error(\"Failed to initialize replica set after \" + maxAttempts + \" attempts\");
          }
          
          print(\"Waiting for primary election...\");
          sleep(15000);
          
          // Verify we have a primary
          const finalStatus = rs.status();
          if (!finalStatus.ok || !finalStatus.members.some(m => m.state === 1)) {
            throw new Error(\"Failed to establish primary after initialization\");
          }
        '
        
        echo 'Creating indexes and initial data...';
        mongosh --host mongodb1 --username root --password example /docker-entrypoint-initdb.d/init.js;
        
        echo 'Replica set initialization complete';
      "
    volumes:
      - ./docker/mongodb/init.js:/docker-entrypoint-initdb.d/init.js:ro
    networks:
      - messaging-net
    restart: "no"

    
  # Redis Cluster 
  redis1:
    image: redis:7.0
    container_name: redis1
    hostname: redis1
    environment:
      REDISCLI_AUTH: redispass
    ports:
      - "6379:6379"
      - "16379:16379"
    command: [
      "redis-server",
      "--cluster-enabled", "yes",
      "--cluster-config-file", "nodes.conf",
      "--cluster-node-timeout", "5000",
      "--requirepass", "redispass",
      "--masterauth", "redispass",
      "--protected-mode", "no",
      "--cluster-announce-ip", "redis1",
      "--cluster-announce-port", "6379",
      "--cluster-announce-bus-port", "16379"
    ]

    volumes:
      - redis1_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "redispass", "ping"]
      interval: 5s
      timeout: 3s
      retries: 3
    networks:
      - messaging-net

  redis2:
    image: redis:7.0
    container_name: redis2
    hostname: redis2
    depends_on:
      - redis1
    environment:
      REDISCLI_AUTH: redispass
    ports:
      - "6380:6379"
      - "16380:16379"
    command: [
      "redis-server",
      "--cluster-enabled", "yes",
      "--cluster-config-file", "nodes.conf",
      "--cluster-node-timeout", "5000",
      "--requirepass", "redispass",
      "--masterauth", "redispass",
      "--protected-mode", "no",
      "--cluster-announce-ip", "redis2",
      "--cluster-announce-port", "6379",
      "--cluster-announce-bus-port", "16379"
    ]

    volumes:
      - redis2_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "redispass", "ping"]
      interval: 5s
      timeout: 3s
      retries: 3
    networks:
      - messaging-net

  redis3:
    image: redis:7.0
    container_name: redis3
    hostname: redis3
    depends_on:
      - redis2
    environment:
      REDISCLI_AUTH: redispass
    ports:
      - "6381:6379"
      - "16381:16379"
    command: [
      "redis-server",
      "--cluster-enabled", "yes",
      "--cluster-config-file", "nodes.conf",
      "--cluster-node-timeout", "5000",
      "--requirepass", "redispass",
      "--masterauth", "redispass",
      "--protected-mode", "no",
      "--cluster-announce-ip", "redis3",
      "--cluster-announce-port", "6379",
      "--cluster-announce-bus-port", "16379"
    ]
    volumes:
      - redis3_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "redispass", "ping"]
      interval: 5s
      timeout: 3s
      retries: 3
    networks:
      - messaging-net

  redis-init:
    image: redis:7.0
    container_name: redis-init
    depends_on:
      redis1:
        condition: service_healthy
      redis2:
        condition: service_healthy
      redis3: 
        condition: service_healthy
    entrypoint: ["bash", "-c", "
      echo 'Waiting for Redis cluster nodes to be ready...';
      sleep 5;
      echo 'Creating Redis cluster...';
      yes yes | redis-cli --cluster create \
        redis1:6379 redis2:6379 redis3:6379 \
        --cluster-replicas 0 \
        -a redispass;
      echo 'Redis cluster initialized.'
      "]
    networks:
      - messaging-net
    restart: "no"

  # Kafka brokers

  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.0
    container_name: zookeeper
    hostname: zookeeper
    environment:
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_INIT_LIMIT: 5
      ZOOKEEPER_SYNC_LIMIT: 2
      ZOOKEEPER_MAX_CLIENT_CNXNS: 60
      ZOOKEEPER_SERVERS: "zookeeper:2888:3888"
      KAFKA_OPTS: "-Dzookeeper.4lw.commands.whitelist=*"
    ports:
      - "2181:2181"
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
      - zookeeper_log:/var/lib/zookeeper/log
    restart: always
    networks:
      - messaging-net

  kafka1:
    image: confluentinc/cp-kafka:7.3.0
    container_name: kafka1
    hostname: kafka1
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"    
      - "29092:29092"  
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka1:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_MIN_INSYNC_REPLICAS: 2
      KAFKA_NUM_PARTITIONS: 3
      KAFKA_LOG_RETENTION_HOURS: 168
    volumes:
      - kafka1_data:/var/lib/kafka/data
    healthcheck:
      test: kafka-topics --bootstrap-server kafka1:9092 --list || exit 1
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - messaging-net

  kafka2:
    image: confluentinc/cp-kafka:7.3.0
    container_name: kafka2
    hostname: kafka2
    depends_on:
      - zookeeper
      - kafka1
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka2:9092,PLAINTEXT_HOST://localhost:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_MIN_INSYNC_REPLICAS: 2
      KAFKA_NUM_PARTITIONS: 3
      KAFKA_LOG_RETENTION_HOURS: 168
    volumes:
      - kafka2_data:/var/lib/kafka/data
    healthcheck:
      test: kafka-topics --bootstrap-server kafka2:9092 --list || exit 1
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - messaging-net

  kafka3:
    image: confluentinc/cp-kafka:7.3.0
    container_name: kafka3
    hostname: kafka3
    depends_on:
      - zookeeper
      - kafka2
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka3:9092,PLAINTEXT_HOST://localhost:9094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_MIN_INSYNC_REPLICAS: 2
      KAFKA_NUM_PARTITIONS: 3
      KAFKA_LOG_RETENTION_HOURS: 168
    volumes:
      - kafka3_data:/var/lib/kafka/data
    healthcheck:
      test: kafka-topics --bootstrap-server kafka3:9092 --list || exit 1
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - messaging-net

  kafka-init:
    image: confluentinc/cp-kafka:7.3.0
    container_name: kafka-init
    depends_on:
      kafka1:
        condition: service_healthy
      kafka2:
        condition: service_healthy
      kafka3:
        condition: service_healthy
    command: >
      bash -c "
        echo 'Waiting for Kafka to be ready...'
        sleep 15
        
        TOPIC_EXISTS=$(kafka-topics --bootstrap-server kafka1:9092 --list | grep '^messages$' || echo '')
        
        if [ -z \"$TOPIC_EXISTS\" ]; then
          echo 'Creating messages topic...'
          kafka-topics --bootstrap-server kafka1:9092 --create --topic messages --partitions 3 --replication-factor 3
          RESULT=$?
          if [ \"$RESULT\" -eq 0 ]; then
            echo 'Topic created successfully'
          else
            echo 'Failed to create topic, but continuing...'
          fi
        else
          echo 'Topic messages already exists, skipping creation'
        fi
        
        echo 'Topic information:'
        kafka-topics --bootstrap-server kafka1:9092 --describe --topic messages
      "
    restart: no
    networks:
      - messaging-net

      
  # Your Application Service
  app:
    build:
      context: .
      dockerfile: Dockerfile
    image: messaging-app:latest
    container_name: messaging-app
    user: "1000"
    ports:
      - "8080:8080"  # HTTP API
      - "8081:8081"  # WebSocket
      - "9091:9091"  # Metrics
    env_file:
      - ".env"
    depends_on:
      mongodb3:
        condition: service_healthy
      redis3:
        condition: service_healthy
      kafka3:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 10s
      timeout: 3s
      retries: 3
    networks:
      - messaging-net



  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    hostname: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./docker/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    depends_on:
      - app
      - redis1
      - mongodb1
      - kafka1
    networks:
      - messaging-net

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    hostname: grafana
    ports:
      - "3030:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./docker/grafana/provisioning:/etc/grafana/provisioning
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
    depends_on:
      - prometheus
    networks:
      - messaging-net

  mongodb-exporter:
    image: bitnami/mongodb-exporter:latest  
    container_name: mongodb-exporter
    environment:
    - MONGODB_URI=mongodb://root:example@mongodb1:27017/admin?replicaSet=rs0&authSource=admin,mongodb://root:example@mongodb3:27017/admin?replicaSet=rs0&authSource=admin,mongodb://root:example@mongodb3:27017/admin?replicaSet=rs0&authSource=admin
    
    # Multi-target configuration
    - SPLIT_CLUSTER=true  # Treat each node as separate target
    - DIRECT_CONNECT=false  # Required for replica sets
    
    # Metrics collection options
    - DISABLED_METRICS=asserts,durability
    - COLLECT_COLLECTION=true
    - COLLECT_DATABASE=true
    - COLLECT_TOPSTATS=true
    - COLLECT_INDEX_STATS=true
    - COLLECT_CONNPOOL_STATS=true
    
    # Collection-level metrics (adjust with your actual collections)
    - COLLSTATS_COLLS=messaging_app.messages,messaging_app.users,messaging_app.friendships
    
    # Debugging
    - LOG_LEVEL=debug
    - COMPATIBLE_MODE=true  
    ports:
      - "9216:9216"
    user: "1000"
    depends_on:
      - mongodb1
      - mongodb2
      - mongodb3
    networks:
      - messaging-net

  redis-exporter:
    image: oliver006/redis_exporter:v1.55.0  
    container_name: redis-exporter
    environment:
      - REDIS_ADDR=redis://redis1:6379
      - REDIS_PASSWORD=redispass
    ports:
      - "9121:9121"
    depends_on:
      - redis1
    networks:
      - messaging-net

volumes:
  prometheus_data:
  grafana_data:
  mongodb1_data:
  mongodb2_data:
  mongodb3_data:
  redis1_data:
  redis2_data:
  redis3_data:
  zookeeper_data:
  zookeeper_log:
  kafka1_data:
  kafka2_data:
  kafka3_data:

networks:
  messaging-net:
    name: messaging-net